{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range-Agnostic Multi-View Depth Estimation With Keyframe Selection\n",
    "\n",
    "This notebook provides a code example to use the pretrained models and reproduce the paper results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Config\n",
    "\n",
    "Choose here the parameters for the following sections, like the device on which run inferences, the dataset etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "device = \"cuda:0\"             # cpu, cuda:<device id>\n",
    "dataset = \"blended\"           # blended | tartanair | unrealstereo4k\n",
    "unreal_benchmark = \"video\"    # video   | stereo\n",
    "sample_idx = 10               # the sample to plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from lib.dataset import (\n",
    "    BlendedMVSDataModule,\n",
    "    TartanairDataModule,\n",
    "    UnrealStereo4kDataModule,\n",
    ")\n",
    "from lib.metrics import compute_metrics, depth_to_disp\n",
    "from lib.visualize import plot_sample\n",
    "from lib.dataset.utils.preprocess import normalize_to_tensor, prepare_input\n",
    "from torchvision import transforms as T\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ramdepth import Model\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "DMClass = {\n",
    "    \"blended\": BlendedMVSDataModule,\n",
    "    \"tartanair\": TartanairDataModule,\n",
    "    \"unrealstereo4k\": UnrealStereo4kDataModule,\n",
    "}[dataset]\n",
    "\n",
    "dm = DMClass(\n",
    "    load_prevs=1\n",
    "    if dataset == \"unrealstereo4k\" and unreal_benchmark == \"stereo\"\n",
    "    else 4,\n",
    "    batch_size=1,\n",
    "    eval_transform=normalize_to_tensor,\n",
    "    **{\"stereo_as_prevs\": unreal_benchmark == \"stereo\"}\n",
    "    if dataset == \"unrealstereo4k\" else {},\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup(\"test\")\n",
    "dl = dm.test_dataloader()\n",
    "\n",
    "# load model\n",
    "model = Model(\n",
    "    pretrained={\n",
    "        \"blended\": \"blended\",\n",
    "        \"unrealstereo4k\": \"blended\",\n",
    "        \"tartanair\": \"tartanair\",\n",
    "    }[dataset],\n",
    "    normalize_pose=not (\n",
    "        dataset == \"unrealstereo4k\"\n",
    "        and unreal_benchmark == \"stereo\"\n",
    "        or dataset == \"tartanair\"\n",
    "    ),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Results\n",
    "\n",
    "In this Section we provide sample code to reproduce the results showed in the main paper, in the cell below you can chose a pre-trained model between tartanair and blended, and the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "unit = \"px\" if dataset == \"unrealstereo4k\" and unreal_benchmark == \"stereo\" else \"m\"\n",
    "for ex in tqdm(dl):\n",
    "    inp = {k: v.to(device) for k, v in prepare_input(ex).items()}\n",
    "    depth = model(\n",
    "        **inp, n_cycles=40 if dataset == \"unrealstereo4k\" else 10,\n",
    "    ).cpu()\n",
    "    mask = ex[\"gt\"] > 0\n",
    "    if dataset == \"unrealstereo4k\" and unreal_benchmark == \"stereo\":\n",
    "        disp = depth_to_disp(depth, ex[\"intrinsics\"], ex[\"position\"], ex[\"position_prev_0\"])\n",
    "        gt_disp = depth_to_disp(ex[\"gt\"], ex[\"intrinsics\"], ex[\"position\"], ex[\"position_prev_0\"])\n",
    "        metrics.append(\n",
    "            {k: v.item() for k, v in compute_metrics(disp, gt_disp, mask).items()}\n",
    "        )\n",
    "    else:\n",
    "        metrics.append(\n",
    "            {k: v.item() for k, v in compute_metrics(depth, ex[\"gt\"], mask).items()}\n",
    "        )\n",
    "metrics = pd.DataFrame(metrics).mean(axis=0)\n",
    "\n",
    "print(f\"== metrics for {dataset} ({unit}) ==\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Results\n",
    "\n",
    "Here we show a simple snippet of code to plot predictions of our framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_iter = iter(dl)\n",
    "for i in range(sample_idx):\n",
    "    ex = next(dl_iter)\n",
    "\n",
    "inp = {k: v.to(device) for k, v in prepare_input(ex).items()}\n",
    "depth = model(\n",
    "    **inp, n_cycles=40 if dataset == \"unrealstereo4k\" else 10,\n",
    ").cpu()\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plot_sample(ex, depth)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramvde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
